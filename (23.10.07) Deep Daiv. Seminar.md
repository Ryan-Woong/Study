
# <span style="color:skyblue">Opening</span>
- Leader: 이성배 Keynote Speech: Trend 설명, 팀 딥다이브 설명.
- LLM  모델
- 프롬프트 엔지니어링 
- QLoRA -> LLM 의 대척점. Small Language Model 이 나옴. 파라미터가 적은데도 LLM 과 비슷한 수준의 성능. 
  LLM 모델의 개인화 가능
  LoRA -> LLM 모델 소형화 / QLoRA -> LoRA를 양자화, 더 가볍게 학습할 수 있는 모델. 개인 PC 에서 사용 가능한 수준으로 구현

# <span style="color:red">Session 1</span> 
## 나와 비슷한 고민을 하는 캐릭터는 누구일까?
- Machine Learning 입문
- Team 최강의 삐약이들

### 서론 
-  사람들이 캐릭터들의 MBTI 에 관심이 증가.
- MBTI의 대중화
### 본론
- E인 사람의 글 / I인 사람의 글 크게 구분해서 분류.
- MBTI 별 사용 빈도 높은 단어 추출 -> Word Cloud
- LDA (잠재 디리클레 할당) : 문서의 집합에서 이 문서가 어떤 단어들로 이루어졌는지 분석
- MBTI 알아내기
	- TF-IDF 텍스트 벡터화 : 특정 단어가 한 문서에서 얼마나 등장하는지 보여주는 가중치.
	- 로지스틱 회귀 사용 -> 이게 뭔데;;;
- 각 MBTI 맞출 확률 60 - 70%의 정확도를 보여줌. -> 전체 MBTI 맞출 확률 약 60% 정도.
- 한계점 
	- 성격과 글의 간격이 넓음.
	- MBTI 별 게시글의 차이. 특정 MBTI는 글을 많이 쓰고 누구는 안 쓴다. 

## 조선왕조실록에 기재된 GPT-4 장원 급제 사건에 대해 알려줘
- Transformer NLP
- Team 왕밤빵
### 서론
- Chat GPT의 등장. GPT-4의 등장.
- GPT가 국내 시험에서도 좋은 성적을?
- PSAT 시험에 적용: 주어진 정보 해석 능력. -> 언어논리 영역.

### 본론
- GPT-4 사용.
- 프롬프팅 기법 사용. -> AI에게 일을 지시하는 일련의 과정 (문장요약->질의응답->코드생성)
- 기본 프롬프팅
	- 단순일치, 단순추론 같은 문제는 고득점
	- 75점. 합격자 평균 80점
- 논문 기반 프롬프팅
	- one-shot 기법
		- 예시를 던져주고 프롬프트 사용
	- 82.5점 
- 문제 유형별 맞춤 프롬프팅
- 한계점
	- 일회성 프롬프트
	- PSAT 관련 지식 필요
	- GPT-4 입력 길이 제한 -> 토큰 수의 한계
	- GPT-4의 성능 문제 -> LLM 모델이 아직 완성 단계가 아님. 

## 너의 목소리를 들려줘: 노이즈 제거 기능 향상
- 오디오 / TTS
- Team 스칼렛

### 서론
- 생활 소음 노이즈 제거
- 음성 향상의 한 부분-> 노이즈 제거
- 음악에 관심이 많은 팀원들
- 데이터만을 보강하여 노이즈 제거 성능 향상 방법? 모델 변경 하지 않고도?

### 본론
- VCTK+DEMAND 데이터 기반.
	- Clean Speech
	- Noisy Speech: 소음이 있는 Clean Speech
	- 이 데이터의 한계
		- 대부분 노이즈가 비슷
		- 노이즈 구간별로 음량이 작은 부분 존재, 학습에 무의미 구간
		- 음성 구분 어려울 수도 있음
	- 한계 극복
		- 새로운 노이즈 교체, 사람 목소리가 없는 노이즈
		- SNR: 의도한 소리에 대한 의도하지 않은 소리의 출력 비율
		- 데이터셋 보강을 위한 맞춤 조정
- 모델 학습
	- CMGAN 모델
	- PESQ 점수 측정
- 의의와 한계
	- 데이터셋 보강 -> 노이즈 제거 모델의 성능 개선
	- 사람 음성 없는 노이즈에 초점 두는 새로운 시도
	- PESQ는 높지만, 노이즈는 덜 잡힘

## 툰픽: 당신을 위한 웹툰 추천 Pick
- 추천 시스템
- Team 망고팀

### 서론
- 추천 시스템이란?
	- 비슷한 컨텐츠 추천: 컨텐츠 기반 필터링
	- 나와 비슷한 사람들이 본 컨텐츠 추천: 협업 필터링
- 웹툰의 대중화, 웹툰의 인기 상승: 드라마 무빙과 마스크걸
- 네이버 웹툰 데이터 수집

### 본론
- 그림체와 스토리에 비중을 둠 -> 2470개의 대표 이미지, 스토리
- 이미지
	- 이미지 분할: 핵심 개체 추출
	- 특성 추출: 이미지 특성 추출 및 임베딩
	- 이미지 유사도 계산
- Image Segmentation
	- Segmentation Anything Model
	- 중심 + 주변 4개의 기준점
- Feature Extraction
	- Style Transfer 기능 일부 사용
- 이미지 유사도 계산
	- Cosine Similarity
- 텍스트 모델 선정
	- 웹툰 소개글을 줄거리로 인식.
	- Sentence-BERT: 문장 임베딩 모델
	- Word2Vec: 단어를 벡터로 표현하는 자연어 처리 기술.
		- 외부 데이터셋 추가: 영화 줄거리 데이터셋 추가
		- 데이터셋의 정확성 개선
	- 최종 텍스트 유사도 모델 = 이미지 유사도 @% + 텍스트 유사도 @%
		- 사용자 별로 @값 입력 받을 수 있게.
- 네이버 VS 팀의 추천 시스템
	- 네이버: 작가와 장르에 기반한 추천
	- 망고팀: 그림체와 줄거리에 기반한 추천
- 한계점
	- Only 네이버 웹툰.
	- 그림체의 정의 모호 
	- etc

## 뇌파를 이용한 조현병 환자 진단
- Medical AI
- Team 타운

### 서론
- 조현병: 환청이 들리고 망상을 하는 병. 인지 기능의 저하, 현실/비현실 구분 기능 저하
- 10대 후반-20대, 발병률 증가
- 마음의 병이 아닌 뇌의 병. 초기 진단 -> 치료 가능

### 본론
- EEG: 뇌파 중에서도 뇌의 전기 신호인 뇌전도
	- 수면 다원 검사 등에서 사용
	- 두피에 전극 부착하는 기기 사용
- 데이터 수집 -> 전처리 -> 모델링 -> 결과 분석
- EEG in 조현병 데이터셋 사용.
- 전처리 -> 원하는 데이터셋만을 남기는 과정
	- Band-Pass Filtering 사용
	- 4-30 hz 주파수만 통과 -> 조현병의 특징이 드러나는 주파수 사용
	- 720초 통일 -> 30초 간격으로 data segmentation
	- segment별로 평균 표준편차 구하고 z-score standarization
-  1D CNN Layer & 2D CNN Layer 모델
- 1D CNN 과 LSTM을 결합한 모델이 가장 성능이 우수했다. 
	- 시간 패턴을 감지하기 + 장기간의 복잡한 패턴을 학습하는데 효과적이다. 
- 한계점
	- 부족한 EEG 데이터셋의 양
	- 2D CNN + LSTM 모델? 조현병 진단 성능 향상?





# <span style="color:red">Session 2</span> 
## 성인 독서량 감소 해결을 위한 선호 영화 기반 도서 추천 시스템            '마음의 냥식' 
### 서론
- 줄어가는 성인 독서량

### 본론
- 데이터 수집
	- 영화 데이터 약 500개의 영화
	- 책 데이터 -> 각종 도서 관련 매체를 통한 책 데이터 수집
	- 왓챠 피디아 영화, 책 평점 데이터 수집
- 영화 줄거리, 책 소개 데이터 토큰화
- 불용어 처리 -> 불필요한 데이터 제거
- 하이브리드 추천 시스템 모델링
	- 유사도 기반 책 추천
	- 영화 줄거리 -책 소개 유사도 측정. -> 코사인 유사도 가중치
	- 영화 - 사용자 - 도서 평점 기반 협업 필터링
	- 영화 줄거리 -책 소개 유사도 값 + 영화 - 사용자 - 도서 평점 기반 협업 필터링 값
- 시사점 및 기대효과
	- 성인 독서 습관 부재 해결
	- 연령별 맞춤 추천으로 확장 가능성
	- 발전 가능성 -> GUI를 활용한 어플 생성 가능
	- 공공 도서관 온/오프라인 접목 가능

### 꿀팁
- 공모전 참여 팁
	- 수상 사례와 평가 기준 함께 보며 가장 유리한 부문 찾기
		- 참가부문, 편가 기준, 수상 사례 복합 분석
	- 공공 데이터 최대한 많이 활용
		- 정부처 포함 외부 공모전에서 적용 가능
		- 대학 입시, 취업 자소서 작성 처럼 문항의 단어 하나하나 분석
		- 공공 데이터는 신뢰성이 높다.
	- 1차 서류 팁
		- 자세히, 그러나 간결한 작성
		- 최대 페이지 수는 꼭 채우기
		- only 읽는 과정으로만 프로젝트 평가, 질의응답 불가
	- 2차 발표 팁
		- 30분도 채 안됨. 
		- 발표 흐름 끊을 것 같은 내용? -> 맨 뒤에 appendix로 추가
		- 심사위원들이 심사하면서 읽을 수 있도록
		- 


## 오늘 어때? : AI 일기장
- NLP Transformer
- Team Chat CBH

### 서론
- 오프라인 일기는 줄었지만 일기를 쓰고자, 또는 쓰는데 도움이 되는 앱은 계속 출시
- 우리에게 익숙한 대화 형식을 활용해서 일기?

### 본론
- 대화 모델
	- LLaMA 파인 튜닝
		- LLAMA 모델: 적은 파라미터로도 좋은 성능
		- 하드웨어 불가능
	- T5 모델 파인 튜닝
	- GPT2 모델 파인 튜닝
		- 뜬끔 없는 질문 -> 데이터 부족, 너무 짧은 대화
	- 그래서 프롬프트 엔지니어링으로 대화모델 생성
		- LangChain 과  프롬프트 엔지니어링 사용
		- Temperature -> 0.5로 지정해 창의적이고 다양한 답변
		- Zero-shot 프롬프팅
		- 프롬프트 조건 확립 -> 보다 나은 답변 도출
- 요약 모델
	- T5 모델 파인 튜닝
	- KoT5-summerization 모델 사용
	- 프롬프트 엔지니어링도 사용
		- GPT 3.5 사용
		- 프롬프트 조건 확립 -> 보다 나은 답변 도출
	- 감정 분류 - 이모지 출력
- 한계점
	- LLM 모델 파인튜닝은 불가능
	- 데이터 양 부족. 
	- 현재는 사건 중심 기록 -> 감정 기록 또한 진행 요망.

## CalCheck: 사진 한 장으로 칼로리 포착
- Deep Learning 입문
- Team IDLE

### 서론
- 딥러닝 -> 컴퓨터 비전과 실전 경험 목표

### 본론
- 데이터 수집
	- 기존 데이터셋 사용
	- AI Hub 데이터 사용 -> 음식 이미지
	- 음식 카테고리 20개로 수축
		- 음식 사진 500개 씩 학습
- 모델
	-  Object Detection 포커스
		- 1stage Detector 채택 -> 객체 크기 이슈 때문에 SSD 모델 사용
		- ~~2stage Detector
		- AP를 평가 지수로 사용
	- 학습 이미지에 다양한 변화를 주면서 학습
	- SSD 모델?
		- 속도와 정확도 사이의 문제 해결
- 한계점
	- 음식 카테고리 수축
	- AP 낮게 나오는 문제

## Book-OST: 책과 음악 데이터 활용을 통한 책에 어울리는 음악 추천 
- 추천 시스템
- Team 시고르자브종

### 서론
- 한국인 독서량 감소
- 젊은 층 문해력 저하
- 책에도 OST가 필요하다 -> JTBC 멜로디 책방에서 영감

### 본론
- 데이터
	- 도서 설명 데이터 -> Daum API 사용: 책소개, 책 일부 발췌 등
	- 노래 데이터: audio feature 수집 노래의 음악적 특징 데이터화 
	- 노래 가사 데이터 
	- 트위터 감정 데이터 ->  문장에서 감정 추출
- 데이터 전처리
- 감정적 특징 유사도 분석
	- 오디오 특징 무드 + 텍스트 특징 무드 결합 필요
	- 오디오 특징 기반 6개, 텍스트 특징 무드 11개 매치
- 내용 특징 유사도 분석
	- 노래 가사 텍스트 - 도서 설명 텍스트 간의 연결
- 최종 모델링
	- 3가지 유사도를 이용해 최종 모델 완성
- 한계점
	- 오디오 피쳐 -> 실제 사람의 감정과 간극
	- 감정 추출 모델의 오류




## 당뇨병 환자의 CAD 동반 질환 예측
- Medicla AI
- Team 

### 서론
- 사망원인 2위 = 심장 질환
- 심혈관 질환 -> 관상동맥 질환으로 엮임
- 관상동맥 질환 예측은 이미 많음, 당뇨병에 집중

### 본론
- 데이터 추출
	- MIMIC-IV 데이터셋 채택: ICU에 입원했었던 환자들의 의료 정보 데이터셋
- 도메인 분석
- 데이터 전처리
	- Column dropping
	- 결측치 처리
	- 범주형 데이터 인코딩
- 모델링
- 결론
	- 당뇨병 환자에게서 CAD는 동반질환으로 나타남.
	- 기타등등 (책자 참조)
- 한계점
	- MIMIC-IV 데이터 셋의 결측치 문제
	- MIMIC-IV 데이터 셋의 모호성
	- 불균형 클래스 데이터


# <span style="color:skyblue">정리</span>  
## 이번 발표에서 느낀 점 / 알게 된 점
-  